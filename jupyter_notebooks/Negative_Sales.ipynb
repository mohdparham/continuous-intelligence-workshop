{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:,.2f}'.format # use 2 decimals, not scientific notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "s3 = s3fs.S3FileSystem(anon=True)\n",
    "s3.ls('twde-datalab/raw')\n",
    "\n",
    "#may require `mkdir data/`\n",
    "s3.get('twde-datalab/raw/quito_stores_sample2016-2017.csv', \n",
    "       '../data/quito_stores_sample2016-2017.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/quito_stores_sample2016-2017.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Starting with `.describe()` is never a bad place to start data exploration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count   5,877,318.00\n",
       "mean           13.85\n",
       "std            30.87\n",
       "min          -290.00\n",
       "25%             3.00\n",
       "50%             7.00\n",
       "75%            14.00\n",
       "max         6,932.00\n",
       "Name: unit_sales, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.unit_sales.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I have questions about those *negative sales*. How do you negative sell something?\n",
    "That's got my gears turning. Here are some of my new questions about the data:\n",
    "- Question: What does a negative sale mean?\n",
    "- Question: How often are sales negative?\n",
    "- Question: How many times are sales above 5,000?\n",
    "- Question: How do the unit_sales numbers vary with the `date` column?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A good way to answer these questions is with some visualizations.\n",
    "\n",
    "It might be difficult to get an intuitive feel of the data by knowing the exact answer to many of those questions. What we actually want to learn is the personality of the data. We want to know what it looks like in a glance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's import the python libraries that do the heavy lifting of data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and then let's look at a box plot of unit sales. A box plot conveys the mean and the middle 50% of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data.unit_sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This box plot is awful.** We can't even recognize the inter-quartile-range. \n",
    "\n",
    "Let's make a decision: **Ignore \"very large\" values** (perhaps to be explored later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = data[data.unit_sales > 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_of_data = data[data.unit_sales <= 1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and once again look at the boxplot of the non-outlier (for lack of a better term) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(majority_of_data.unit_sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm surprised. This plot isn't any better than the first one. Let's try a different visualization... Maybe kernel density estimation plot. \n",
    "\n",
    "This shows us the probability of a data point being a certain value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(majority_of_data.unit_sales, clip=[-100,500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the likelihood of getting a certain unit_sales value tapers off dramatically and has almost vanished by a unit_sales of 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'd also like to know how do sales change over time. \n",
    "**Is there a weekly cycle? A monthly cycle?**\n",
    "Let's look at that with a line graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, we convert the date column into a datetime object, and set it as the index\n",
    "Then we find the weekly average of the data and plot it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.index = pd.to_datetime(data.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.unit_sales.resample('W').mean().plot(x='index',y='unit_sales')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see something that seems interesting around December-January. We also see what appears to be a couple sales cycles throughout the year. \n",
    "\n",
    "**What do you think causes the huge drop off in August-September?**\n",
    "\n",
    "I'm curious to see if returns happen more frequently after Christmas, so I'm going to repeat the above plot, but only focusing on returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.unit_sales < 0].unit_sales.resample('W').mean().plot(x='index',y='unit_sales')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph is surprising to me. Is it surprising to you? I still strongly suspect that returns happen at a statistically significantly different rate after Christmas, given that purchases spike around Dec-Jan anyway.  My next thought is about those outliers. Maybe `mean` isn't the right measurement to use, since means can be skewed by outliers. \n",
    "\n",
    "Let's see the same graph as above, only this time using `median` as the measurement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.unit_sales < 0].unit_sales.resample('W').median().plot(x='index',y='unit_sales')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There we go. Look at that. When we use a statistic that is robust to outliers, we can see that return behavior is very different around Christmas.\n",
    "\n",
    "What can we do with this knowledge? If we're to predict sales and returns for the end of December and beginning of January, our model should incorporate the effect of Christmas on sales. Perhaps it'd be useful to add columns called, `is_two_weeks_before_christmas` and `is_two_weeks_after_christmas`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import urllib.request\n",
    "# import argparse\n",
    "\n",
    "# def load_data(path, key):\n",
    "#     gcsBucket = \"continuous-intelligence\"\n",
    "\n",
    "#     if not os.path.exists(path):\n",
    "#         os.makedirs(path)\n",
    "\n",
    "#     if not os.path.exists(os.path.join(path, key)):\n",
    "#         url = \"https://storage.googleapis.com/%s/%s\" % (gcsBucket, key)\n",
    "#         urllib.request.urlretrieve(url, os.path.join(path, key))\n",
    "\n",
    "# load_data(path='data/raw', key='store47-2016.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
